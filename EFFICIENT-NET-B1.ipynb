{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "import cv2 as cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdir=r'/content/drive/MyDrive/DATA_VIDEO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = []\n",
    "labels = []\n",
    "classlist = os.listdir(sdir)\n",
    "for klass in classlist:\n",
    "    classpath = os.path.join(sdir, klass)\n",
    "    flist = os.listdir(classpath)\n",
    "    for f in flist:\n",
    "        fpath = os.path.join(classpath, f)\n",
    "        filepaths.append(fpath)\n",
    "        labels.append(klass)\n",
    "df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, testing, and validation sets\n",
    "train_df, test_valid_df = train_test_split(df, test_size=0.2, random_state=123)\n",
    "test_df, valid_df = train_test_split(test_valid_df, test_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for augmented images\n",
    "working_dir = r'./'\n",
    "dest_dir = os.path.join(working_dir, 'aug')\n",
    "if os.path.isdir(dest_dir):\n",
    "    shutil.rmtree(dest_dir)\n",
    "os.mkdir(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform augmentation for each class individually\n",
    "for klass in classlist:\n",
    "    os.mkdir(os.path.join(dest_dir, klass))\n",
    "\n",
    "    # Augment only the training data\n",
    "    group = train_df[train_df['labels'] == klass]\n",
    "    sample_count = len(group)\n",
    "    target_dir = os.path.join(dest_dir, klass)\n",
    "\n",
    "    # Augmentation parameters\n",
    "    target_size =1000\n",
    "    batch_size = 1\n",
    "    gen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2\n",
    "    )\n",
    "    aug_gen = gen.flow_from_dataframe(\n",
    "        group,\n",
    "        x_col='filepaths',\n",
    "        y_col=None,\n",
    "        target_size=target_size,\n",
    "        class_mode=None,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        save_to_dir=target_dir,\n",
    "        save_prefix='aug-',\n",
    "        save_format='jpg'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate augmented images\n",
    "aug_img_count = 0\n",
    "delta = target - sample_count\n",
    "while aug_img_count < delta:\n",
    "  images = next(aug_gen)\n",
    "  aug_img_count += len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate original and augmented dataframes\n",
    "aug_filepaths = []\n",
    "aug_labels = []\n",
    "for klass in classlist:\n",
    "    classpath = os.path.join(dest_dir, klass)\n",
    "    flist = os.listdir(classpath)\n",
    "    for f in flist:\n",
    "        fpath = os.path.join(classpath, f)\n",
    "        aug_filepaths.append(fpath)\n",
    "        aug_labels.append(klass)\n",
    "\n",
    "aug_df = pd.DataFrame({'filepaths': aug_filepaths, 'labels': aug_labels})\n",
    "train_df = pd.concat([df, aug_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print lengths of train, test, and validation sets\n",
    "print('train_df length:', len(train_df))\n",
    "print('test_df length:', len(test_df))\n",
    "print('valid_df length:', len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height=250\n",
    "width=250\n",
    "channels=3\n",
    "batch_size=40\n",
    "img_shape=(height, width, channels)\n",
    "img_size=(height, width)\n",
    "length=len(test_df)\n",
    "test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]\n",
    "test_steps=int(length/test_batch_size)\n",
    "print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\n",
    "def scalar(img):\n",
    "    #img=img/127.5-1\n",
    "    return img\n",
    "trgen=ImageDataGenerator(preprocessing_function=scalar, horizontal_flip=True)\n",
    "tvgen=ImageDataGenerator(preprocessing_function=scalar)\n",
    "sdir=r'../input/mars-surface-and-curiosity-image-set-nasa/Mars Surface and Curiosity Image/images'\n",
    "train_gen=trgen.flow_from_dataframe( train_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "test_gen=tvgen.flow_from_dataframe( test_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "valid_gen=tvgen.flow_from_dataframe( valid_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "classes=list(train_gen.class_indices.keys())\n",
    "class_count=len(classes)\n",
    "train_steps=int(len(train_gen.labels)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_samples(gen ):\n",
    "    t_dict=gen.class_indices\n",
    "    classes=list(t_dict.keys())\n",
    "    images,labels=next(gen) # get a sample batch from the generator\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    length=len(labels)\n",
    "    if length<25:   #show maximum of 25 images\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    for i in range(r):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image=images[i]/255\n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color='blue', fontsize=16)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_samples(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_in_color(txt_msg,fore_tupple,back_tupple,):\n",
    "    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple\n",
    "    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n",
    "    rf,gf,bf=fore_tupple\n",
    "    rb,gb,bb=back_tupple\n",
    "    msg='{0}' + txt_msg\n",
    "    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m'\n",
    "    print(msg .format(mat), flush=True)\n",
    "    print('\\33[0m', flush=True) # returns default print color to back to black\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='EfficientNetB1'\n",
    "base_model=tf.keras.applications.EfficientNetB1(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max')\n",
    "x=base_model.output\n",
    "x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
    "x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "x=Dropout(rate=.45, seed=123)(x)\n",
    "output=Dense(class_count, activation='softmax')(x)\n",
    "model=Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(Adamax(learning_rate=.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRA(keras.callbacks.Callback):\n",
    "    reset=False\n",
    "    count=0\n",
    "    stop_count=0\n",
    "    tepochs=0\n",
    "    def __init__(self,model, patience,stop_patience, threshold, factor, dwell, model_name, freeze,batches, initial_epoch):\n",
    "        super(LRA, self).__init__()\n",
    "        self.model=model\n",
    "        self.patience=patience # specifies how many epochs without improvement before learning rate is adjusted\n",
    "        self.stop_patience=stop_patience\n",
    "        self.threshold=threshold # specifies training accuracy threshold when lr will be adjusted based on validation loss\n",
    "        self.factor=factor # factor by which to reduce the learning rate\n",
    "        self.dwell=dwell\n",
    "        self.lr=float(tf.keras.backend.get_value(model.optimizer.lr)) # get the initiallearning rate and save it in self.lr\n",
    "        self.highest_tracc=0.0 # set highest training accuracy to 0\n",
    "        self.lowest_vloss=np.inf # set lowest validation loss to infinity\n",
    "        #self.count=0 # initialize counter that counts epochs with no improvement\n",
    "        #self.stop_count=0 # initialize counter that counts how manytimes lr has been adjustd with no improvement\n",
    "        self.initial_epoch=initial_epoch\n",
    "        self.batches=batches\n",
    "        #self.epochs=epochs\n",
    "        best_weights=self.model.get_weights() # set a class vaiable so weights can be loaded after training is completed\n",
    "        msg=' '\n",
    "        if freeze==True:\n",
    "            msgs=f' Starting training using  base model { model_name} with weights frozen to imagenet weights initializing LRA callback'\n",
    "        else:\n",
    "            msgs=f' Starting training using base model { model_name} training all layers '\n",
    "        print_in_color (msgs, (244, 252, 3), (55,65,80))\n",
    "    def on_train_begin(self, logs=None):\n",
    "        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:^8s}'.format('Epoch', 'Loss', 'Accuracy',\n",
    "                                                                                              'V_loss','V_acc', 'LR', 'Next LR', 'Monitor', 'Duration')\n",
    "        print_in_color(msg, (244,252,3), (55,65,80))\n",
    "    def on_train_end(self, logs=None):\n",
    "        model.set_weights(LRA.best_weights)\n",
    "        msg='Training is completed - model is set with weights for the epoch with the lowest loss'\n",
    "        print_in_color(msg, (0,255,0), (55,65,80))\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        acc=logs.get('accuracy')* 100  # get training accuracy\n",
    "        loss=logs.get('loss')\n",
    "        msg='{0:20s}processing batch {1:4s} of {2:5s} accuracy= {3:8.3f}  loss: {4:8.5f}'.format(' ', str(batch), str(self.batches), acc, loss)\n",
    "        print(msg, '\\r', end='') # prints over on the same line to show running batch count\n",
    "\n",
    "\n",
    "    def on_epoch_begin(self,epoch, logs=None):\n",
    "        self.now= time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n",
    "        later=time.time()\n",
    "        duration=later-self.now\n",
    "        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "        current_lr=lr\n",
    "        v_loss=logs.get('val_loss')  # get the validation loss for this epoch\n",
    "        acc=logs.get('accuracy')  # get training accuracy\n",
    "        v_acc=logs.get('val_accuracy')\n",
    "        loss=logs.get('loss')\n",
    "        #print ( '\\n',v_loss, self.lowest_vloss, acc, self.highest_tracc)\n",
    "        if acc < self.threshold: # if training accuracy is below threshold adjust lr based on training accuracy\n",
    "            monitor='accuracy'\n",
    "            if acc>self.highest_tracc: # training accuracy improved in the epoch\n",
    "                self.highest_tracc=acc # set new highest training accuracy\n",
    "                LRA.best_weights=self.model.get_weights() # traing accuracy improved so save the weights\n",
    "                self.count=0 # set count to 0 since training accuracy improved\n",
    "                self.stop_count=0 # set stop counter to 0\n",
    "                if v_loss<self.lowest_vloss:\n",
    "                    self.lowest_vloss=v_loss\n",
    "                color= (0,255,0)\n",
    "                self.lr=lr\n",
    "            else:\n",
    "                # training accuracy did not improve check if this has happened for patience number of epochs\n",
    "                # if so adjust learning rate\n",
    "                if self.count>=self.patience -1:\n",
    "                    color=(245, 170, 66)\n",
    "                    self.lr= lr* self.factor # adjust the learning by factor\n",
    "                    tf.keras.backend.set_value(self.model.optimizer.lr, self.lr) # set the learning rate in the optimizer\n",
    "                    self.count=0 # reset the count to 0\n",
    "                    self.stop_count=self.stop_count + 1\n",
    "                    if self.dwell:\n",
    "                        self.model.set_weights(LRA.best_weights) # return to better point in N space\n",
    "                    else:\n",
    "                        if v_loss<self.lowest_vloss:\n",
    "                            self.lowest_vloss=v_loss\n",
    "                else:\n",
    "                    self.count=self.count +1 # increment patience counter\n",
    "        else: # training accuracy is above threshold so adjust learning rate based on validation loss\n",
    "            monitor='val_loss'\n",
    "            if v_loss< self.lowest_vloss: # check if the validation loss improved\n",
    "                self.lowest_vloss=v_loss # replace lowest validation loss with new validation loss\n",
    "                LRA.best_weights=self.model.get_weights() # validation loss improved so save the weights\n",
    "                self.count=0 # reset count since validation loss improved\n",
    "                self.stop_count=0\n",
    "                color=(0,255,0)\n",
    "                self.lr=lr\n",
    "            else: # validation loss did not improve\n",
    "                if self.count>=self.patience-1:\n",
    "                    color=(245, 170, 66)\n",
    "                    self.lr=self.lr * self.factor # adjust the learning rate\n",
    "                    self.stop_count=self.stop_count + 1 # increment stop counter because lr was adjusted\n",
    "                    self.count=0 # reset counter\n",
    "                    tf.keras.backend.set_value(self.model.optimizer.lr, self.lr) # set the learning rate in the optimizer\n",
    "                    if self.dwell:\n",
    "                        self.model.set_weights(LRA.best_weights) # return to better point in N space\n",
    "                else:\n",
    "                    self.count =self.count +1 # increment the patience counter\n",
    "                if acc>self.highest_tracc:\n",
    "                    self.highest_tracc= acc\n",
    "        msg=f'{str(epoch+1):^3s}/{str(LRA.tepochs):4s} {loss:^9.3f}{acc*100:^9.3f}{v_loss:^9.5f}{v_acc*100:^9.3f}{current_lr:^9.5f}{self.lr:^9.5f}{monitor:^11s}{duration:^8.2f}'\n",
    "        print_in_color (msg,color, (55,65,80))\n",
    "        if self.stop_count> self.stop_patience - 1: # check if learning rate has been adjusted stop_count times with no improvement\n",
    "            msg=f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n",
    "            print_in_color(msg, (0,255,0), (55,65,80))\n",
    "            self.model.stop_training = True # stop training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =10\n",
    "patience= 1 # number of epochs to wait to adjust lr if monitored value does not improve\n",
    "stop_patience =3 # number of epochs to wait before stopping training if monitored value does not improve\n",
    "threshold=.9 # if train accuracy is < threshhold adjust monitor accuracy, else monitor validation loss\n",
    "factor=.5 # factor to reduce lr by\n",
    "dwell=True # experimental, if True and monitored metric does not improve on current epoch set  modelweights back to weights of previous epoch\n",
    "freeze=False # if true free weights of  the base model\n",
    "batches=train_steps\n",
    "callbacks=[LRA(model=model,patience=patience,stop_patience=stop_patience, threshold=threshold,factor=factor,dwell=dwell, model_name=model_name, freeze=freeze, batches=batches,initial_epoch=0 )]\n",
    "LRA.tepochs=epochs  # used to determine value of last epoch for printing\n",
    "history=model.fit(x=train_gen,  epochs=epochs, verbose=0, callbacks=callbacks, validation_data=valid_gen,validation_steps=None,  shuffle=False,  initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"effnet_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# # Load the trained model\n",
    "model = load_model('effnet_1.h5')\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['Antracanose', 'Black Pod Rot', 'Healthy', 'Fito', 'Monilia', 'Sana', 'Stem Cranker']\n",
    "\n",
    "# Function to preprocess an image and predict its class\n",
    "def predict_image_class(image_path):\n",
    "    # Load and preprocess the image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (250, 250)) / 255.0  # Resize and normalize pixel values\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(img)\n",
    "\n",
    "    # Get the predicted class index\n",
    "    predicted_class_index = np.argmax(prediction)\n",
    "\n",
    "    # Get the predicted class label\n",
    "    # predicted_class_label = class_labels[predicted_class_index]\n",
    "    print(prediction)\n",
    "\n",
    "    return predicted_class_index\n",
    "\n",
    "# Specify the path to the input image\n",
    "image_path = '/content/drive/MyDrive/DATA_VIDEO/Healthy/-5805312977254070898_121-14_13_39.jpg'  # Replace 'path_to_your_image.jpg' with the actual path to your image file\n",
    "\n",
    "# Predict the class of the input image\n",
    "predicted_class = predict_image_class(image_path)\n",
    "print(\"Predicted Class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
